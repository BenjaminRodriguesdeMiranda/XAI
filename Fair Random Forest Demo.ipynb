{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb2f2c",
   "metadata": {},
   "source": [
    "# Fair Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97243042",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99468efd-a428-4207-a640-4203f53f8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import lime\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c2a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24978cb8-5f29-4a4c-9cd6-1f52bd475639",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputVar = 'Risk'\n",
    "\n",
    "# this set will be used for training the model, as well as evaluation set for cross-validation\n",
    "X_train = train.drop(columns= [outputVar],axis=1)\n",
    "y_train = train[outputVar]\n",
    "\n",
    "# this set will be used for testing final model performance \n",
    "X_test = test.drop(columns= [outputVar],axis=1)\n",
    "y_test = test[outputVar]\n",
    "\n",
    "X_train = X_train.drop(columns = [\"Checking account_Missing\", \"Saving accounts_Missing\"])\n",
    "X_test = X_test.drop(columns = [\"Checking account_Missing\", \"Saving accounts_Missing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dae54",
   "metadata": {},
   "source": [
    "## Training our demonstration classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e41e5",
   "metadata": {},
   "source": [
    "Over the course of this notebook, we will be using this random forest classifier to demonstrate different measures of fairness that we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d59759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tempForest = RandomForestClassifier(random_state = 0)\n",
    "_ = tempForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3cd93",
   "metadata": {},
   "source": [
    "## Finding Risk Percentages for Males and Females using the Trained Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3ef56",
   "metadata": {},
   "source": [
    "Given model _myModel_ and dataframe _df_, this function finds the percentages of bad customers for males and females in _df_ according to _myModel_. These percentages will be referred to as $Risk_{male}$ and $Risk_{female}$, respectively.\n",
    "\n",
    "The function also returns _genderGap_, which is calulated by the formula $|Risk_{male} - Risk_{female}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60f0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGenderGap(df, myModel):\n",
    "    males = df.loc[df['Sex_female'] == 0]\n",
    "    females = df.loc[df['Sex_female'] == 1]\n",
    "    \n",
    "    X_males = males.drop(columns=[outputVar],axis=1)\n",
    "    y_males = males[outputVar]\n",
    "\n",
    "    X_females = females.drop(columns=[outputVar],axis=1)\n",
    "    y_females = females[outputVar]\n",
    "    \n",
    "    malePredictions = myModel.predict(X_males)\n",
    "    femalePredictions = myModel.predict(X_females)\n",
    "    \n",
    "    maleRiskPercent = np.count_nonzero(malePredictions == True)/malePredictions.shape[0]\n",
    "    femaleRiskPercent = np.count_nonzero(femalePredictions == True)/femalePredictions.shape[0]\n",
    "    \n",
    "    genderGap = abs(maleRiskPercent - femaleRiskPercent)\n",
    "    return maleRiskPercent, femaleRiskPercent, genderGap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1370a",
   "metadata": {},
   "source": [
    "Testing this function on the Random Forest Classifier (Training and Test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0539ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28113879003558717, 0.35294117647058826, 0.07180238643500109)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleRiskPercent, femaleRiskPercent, genderGap = getGenderGap(train, tempForest)\n",
    "maleRiskPercent, femaleRiskPercent, genderGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c845a46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1484375, 0.19444444444444445, 0.04600694444444445)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleRiskPercent, femaleRiskPercent, genderGap = getGenderGap(test, tempForest)\n",
    "maleRiskPercent, femaleRiskPercent, genderGap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021c0e8",
   "metadata": {},
   "source": [
    "## Finding Risk Percentages for People with different Housing Situations using the Trained Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee1e3f",
   "metadata": {},
   "source": [
    "Given model _myModel_ and dataframe _df_, this function finds the percentages of bad customers for people with different housing situations in _df_ according to _myModel_. These percentages will be referred to as $Risk_{own}$, $Risk_{rent}$ and $Risk_{free}$, respectively.\n",
    "\n",
    "The function also returns _housingGap_, which is calculated by $|Risk_{own} - Risk_{rent}| + |Risk_{own} - Risk_{free}| + |Risk_{rent} - Risk_{free}|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8792b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHousingGap(df, myModel):\n",
    "    own = df.loc[df['Housing_own'] == 1]\n",
    "    rent = df.loc[df['Housing_rent'] == 1]\n",
    "    free = df.loc[df['Housing_free'] == 1]\n",
    "    \n",
    "    X_own = own.drop(columns=[outputVar],axis=1)\n",
    "    y_own = own[outputVar]\n",
    "    \n",
    "    X_rent = rent.drop(columns=[outputVar],axis=1)\n",
    "    y_rent = rent[outputVar]\n",
    "    \n",
    "    X_free = free.drop(columns=[outputVar],axis=1)\n",
    "    y_free = free[outputVar]\n",
    "    \n",
    "    ownPredictions = myModel.predict(X_own)\n",
    "    rentPredictions = myModel.predict(X_rent)\n",
    "    freePredictions = myModel.predict(X_free)\n",
    "    \n",
    "    ownRiskPercent = np.count_nonzero(ownPredictions == True)/ownPredictions.shape[0]\n",
    "    rentRiskPercent = np.count_nonzero(rentPredictions == True)/rentPredictions.shape[0]\n",
    "    freeRiskPercent = np.count_nonzero(freePredictions == True)/freePredictions.shape[0]\n",
    "    \n",
    "    housingGap = abs(ownRiskPercent - rentRiskPercent)\n",
    "    + abs(ownRiskPercent - freeRiskPercent)\n",
    "    + abs(rentRiskPercent - freeRiskPercent)\n",
    "    return ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1951c81",
   "metadata": {},
   "source": [
    "Testing this function on the Random Forest Classifier (Training and Test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41993f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26223776223776224,\n",
       " 0.4125874125874126,\n",
       " 0.38823529411764707,\n",
       " 0.15034965034965037)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap = getHousingGap(train, tempForest)\n",
    "ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c937b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11347517730496454,\n",
       " 0.3888888888888889,\n",
       " 0.13043478260869565,\n",
       " 0.27541371158392436)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap = getHousingGap(test, tempForest)\n",
    "ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfc597",
   "metadata": {},
   "source": [
    "## Finding Inequality using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02735634",
   "metadata": {},
   "source": [
    "As defined in this project, $inequality = |Risk_{male} - Risk_{female}| + |Risk_{own} - Risk_{rent}| + |Risk_{own} - Risk_{free}| + |Risk_{rent} - Risk_{free}|$. ($inequality$ is therefore equal to the sum of _genderGap_ and _housingGap_.)\n",
    "\n",
    "To ensure the accuracy of  the $inequality$ metric, we use a cross-validation approach. Here, we use 10 folds, where for each fold, $inequality$ is measured when the model is trained on the rest of the train dataset. Then, the mean of these $inequality$ values that were sampled is used to return the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc948d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "def getInequalityCV(myModel):\n",
    "    \n",
    "    inequalities = np.array([])\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = 0)\n",
    "    \n",
    "    mySplits = kf.split(X_train, y_train)\n",
    "    for trainFold, evalFold in mySplits:\n",
    "        X_train_temp = X_train.loc[trainFold]\n",
    "        y_train_temp = y_train.loc[trainFold]\n",
    "\n",
    "        evalTemp = train.loc[evalFold]\n",
    "\n",
    "        myModel.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "        maleRiskPercent, femaleRiskPercent, genderGap = getGenderGap(evalTemp, myModel)\n",
    "        ownRiskPercent, rentRiskPercent, freeRiskPercent, housingGap = getHousingGap(evalTemp, myModel)\n",
    "        \n",
    "        inequality = genderGap + housingGap\n",
    "        \n",
    "        inequalities = np.append(inequalities, inequality)\n",
    "        \n",
    "    return inequalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196a46a",
   "metadata": {},
   "source": [
    "Testing this function on the random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9613ded9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26499386043387646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getInequalityCV(tempForest).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b49eb0",
   "metadata": {},
   "source": [
    "## Setting up the Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4995684",
   "metadata": {},
   "source": [
    "To evaluate the performance of the model, we use the function $f(p) = -auc\\_score + c * inequality$.\n",
    "\n",
    "This function balances the maximization of $auc\\_score$ and the minimization of $inequality$ using weight $c$. As model evaluation metric, $auc\\_score$ was chosen as it balances false positives and false negatives. Again, we use cross-validation to ensure reliability of the $auc\\_score$ metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b467add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "myRandom = 0\n",
    "c = 1\n",
    "\n",
    "def objective(trial):\n",
    "    tempForest = RandomForestClassifier(random_state = 0)\n",
    "    \n",
    "    global myRandom\n",
    "    myCV = StratifiedKFold(n_splits=10, shuffle=True, random_state=myRandom)\n",
    "    auc = cross_val_score(tempForest, X_train, y_train, scoring = 'roc_auc', cv = myCV).mean()\n",
    "    inequality = getInequalityCV(tempForest).mean()\n",
    "    myRandom = myRandom + 1\n",
    "    \n",
    "    result = -auc + c * inequality\n",
    "    return auc, inequality, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bc11f",
   "metadata": {},
   "source": [
    "This is our $auc\\_score$, $inequality$, and $f(p)$ value for the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334f7810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6769295725108225, 0.26499386043387646, -0.41193571207694607)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e03295",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d562cb1",
   "metadata": {},
   "source": [
    "- Check metrics before & after optimization of $c$\n",
    "  - Accuracy (ROC_AUC)\n",
    "  - Inequality\n",
    "  - Risk Percentages for different subgroups\n",
    "  - Graph with c on x axis, inequality and accuracy on y axis\n",
    "  - Graph with c on x axis, and risk percentages on y axis\n",
    "  \n",
    "- Analyse model before & after optimization of $c$ using LIME & SHAP\n",
    "- Use other models (logistic regression, decision tree, bayesian classifier) and see how they perform regarding metrics (only if time allows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
